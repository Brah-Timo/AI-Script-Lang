import torch
import cv2
import numpy as np
from model import SceneUnderstandingModel
import torchvision.transforms as transforms
from PIL import Image

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ù‹Ø§ØŒ ÙˆØ¥Ù„Ø§ CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
model = SceneUnderstandingModel().to(device)
model.load_state_dict(torch.load("scene_model.pth", map_location=device))
model.eval()

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Tensor Ù…Ø¹ ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ…
transform = transforms.Compose([
    transforms.Resize((512, 512)),  
    transforms.ToTensor(),  
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def analyze_scene(image_path):
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ."""
    image = Image.open(image_path).convert("RGB")  
    image_tensor = transform(image).unsqueeze(0).to(device)  

    with torch.no_grad():
        scene_info = model(image_tensor)

    return scene_info.cpu().numpy()  # Ø¥Ø±Ø¬Ø§Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯

# ØªØ¬Ø±Ø¨Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯
if __name__ == "__main__":
    scene_data = analyze_scene("scene.jpg")
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯:")
    print(scene_data)
