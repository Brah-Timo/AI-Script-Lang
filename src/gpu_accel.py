import numpy as np
import cupy as cp  # Ù…ÙƒØªØ¨Ø© CUDA Ù„Ù„ØªØ³Ø±ÙŠØ¹ Ø¹Ù„Ù‰ GPU

class GPUAccelerator:
    def __init__(self):
        self.memory_pool = cp.cuda.MemoryPool()  # ØªØ­Ø³ÙŠÙ† Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        cp.cuda.set_allocator(self.memory_pool.malloc)

    def execute_matrix_mul(self, A, B):
        """ ØªÙ†ÙÙŠØ° Ø¶Ø±Ø¨ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø¹Ù„Ù‰ GPU Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CuPy """
        A_gpu = cp.asarray(A)
        B_gpu = cp.asarray(B)
        result_gpu = cp.dot(A_gpu, B_gpu)
        return cp.asnumpy(result_gpu)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ CPU

    def accelerate_tensor_ops(self, tensor):
        """ ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU """
        tensor_gpu = cp.asarray(tensor)
        return cp.asnumpy(cp.exp(tensor_gpu))  # ØªÙ†ÙÙŠØ° Ø¯Ø§Ù„Ø© Ø§Ù„Ø£ÙØ³ Ø¹Ù„Ù‰ GPU

    def optimize_large_data(self, data):
        """ ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø®Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CuPy """
        data_gpu = cp.asarray(data)
        return cp.asnumpy(cp.log1p(data_gpu))  # ØªÙ†ÙÙŠØ° log(1 + x) Ø¹Ù„Ù‰ GPU

    def transfer_data_to_gpu(self, data):
        """ ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª NumPy Ø¥Ù„Ù‰ CuPy Ù„Ù†Ù‚Ù„Ù‡Ø§ Ø¥Ù„Ù‰ GPU """
        return cp.asarray(data)

    def transfer_data_to_cpu(self, data_gpu):
        """ ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª CuPy Ø¥Ù„Ù‰ NumPy Ù„Ù†Ù‚Ù„Ù‡Ø§ Ø¥Ù„Ù‰ CPU """
        return cp.asnumpy(data_gpu)

# Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…:
if __name__ == "__main__":
    gpu = GPUAccelerator()

    A = np.random.rand(4, 4)
    B = np.random.rand(4, 4)
    print("ğŸ”¹ GPU Matrix Multiplication Result:\n", gpu.execute_matrix_mul(A, B))

    tensor = np.random.rand(5, 5)
    print("ğŸ”¹ GPU Tensor Exponential Result:\n", gpu.accelerate_tensor_ops(tensor))

    large_data = np.random.rand(1000, 1000)
    print("ğŸ”¹ Optimized Large Data Computation:\n", gpu.optimize_large_data(large_data))
